{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.504387Z",
     "start_time": "2025-05-25T23:16:36.279475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "#\n",
    "import importlib\n",
    "import utilities.lstm_utils as lstm_utils"
   ],
   "id": "9be531e52190f129",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.510114Z",
     "start_time": "2025-05-25T23:16:40.507745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "6853a9962a424a1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing Data",
   "id": "fe8516df25855518"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.596466Z",
     "start_time": "2025-05-25T23:16:40.554317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_time_series = pd.read_csv('../../../data/df_monthly_returns_complete_percentage.csv', index_col='Date')\n",
    "\n",
    "df_time_series = df_time_series.loc[:, ~df_time_series.columns.str.contains('^Unnamed')]"
   ],
   "id": "4513018354bbc541",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.610151Z",
     "start_time": "2025-05-25T23:16:40.607060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "df_time_series_plus1 = df_time_series\n",
    "df_time_series = df_time_series - 1"
   ],
   "id": "b8263a875e7a6a1c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalisation",
   "id": "c64a95d1ae4bdac4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.629275Z",
     "start_time": "2025-05-25T23:16:40.625002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' \n",
    "df_ts_torch = torch.from_numpy(df_time_series.values)\n",
    "# Reshape to (num_samples, num_features) for normalization\n",
    "df_ts_flat = df_ts_torch.view(-1, df_ts_torch.shape[-1])  # Shape: (1000*300, 5)\n",
    "\n",
    "# Calculate min and max per feature\n",
    "df_min = df_ts_flat.min(dim=0, keepdim=True)[0]\n",
    "df_max = df_ts_flat.max(dim=0, keepdim=True)[0]\n",
    "\n",
    "# Apply Min-Max normalization\n",
    "df_ts_normalised = (df_ts_flat - df_min) / (df_max - df_min)\n",
    "\n",
    "# Reshape back to original shape\n",
    "df_time_series_torch = df_ts_normalised.view(df_ts_torch.shape)\n",
    "'''\n"
   ],
   "id": "78b25301531f46d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ndf_ts_torch = torch.from_numpy(df_time_series.values)\\n# Reshape to (num_samples, num_features) for normalization\\ndf_ts_flat = df_ts_torch.view(-1, df_ts_torch.shape[-1])  # Shape: (1000*300, 5)\\n\\n# Calculate min and max per feature\\ndf_min = df_ts_flat.min(dim=0, keepdim=True)[0]\\ndf_max = df_ts_flat.max(dim=0, keepdim=True)[0]\\n\\n# Apply Min-Max normalization\\ndf_ts_normalised = (df_ts_flat - df_min) / (df_max - df_min)\\n\\n# Reshape back to original shape\\ndf_time_series_torch = df_ts_normalised.view(df_ts_torch.shape)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LSTM Model",
   "id": "d5b44de5e3c4223c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.647819Z",
     "start_time": "2025-05-25T23:16:40.644341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=1, output_size=1, learning_rate=0.001, dropout=0.2): # , hidden_size=128\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # LSTM for time-series data (stock returns)\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            # num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "        # FC layer for final prediction\n",
    "        self.fc_final = nn.Linear(hidden_size, 12)\n",
    "\n",
    "    def forward(self, ts_batch): # ts_batch (64, 1653, 10), static_data (64, 1653, 44)\n",
    "        # Time-Series Data\n",
    "        # Reshape dynamic data for LSTM (requires time-step as 2nd dimension)\n",
    "        batch_size, num_stocks, sequence_length = ts_batch.shape[0], ts_batch.shape[1], ts_batch.shape[2]\n",
    "        ts_batch_reshaped = ts_batch.view(batch_size * num_stocks, sequence_length)\n",
    "        #\n",
    "        ts_output_1, (hidden, cell)  = self.lstm(ts_batch_reshaped) # ts_batch_reshaped\n",
    "\n",
    "        ts_output = ts_output_1.view(batch_size, num_stocks, self.hidden_size)\n",
    "        #\n",
    "        # ts_output_2 = self.fc_lstm(ts_output)\n",
    "        #fc_final = nn.Linear(sequence_length, 1)\n",
    "        # prediction =   # (64, 1653, 10)\n",
    "\n",
    "        return self.fc_final(ts_output)#.squeeze(-1) # ts_output_2"
   ],
   "id": "ff4cbc246759fc20",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:40.663221Z",
     "start_time": "2025-05-25T23:16:40.660770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set sequence length (12 months)\n",
    "in_seq_length = 12\n",
    "out_seq_length = 12"
   ],
   "id": "4bb4ad974e9f4f73",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LSTM Univariate - 1 Month",
   "id": "d5318687c5affaa7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:41.445466Z",
     "start_time": "2025-05-25T23:16:40.676639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(lstm_utils)\n",
    "\n",
    "# Set sequence length (e.g., 12 time points)\n",
    "X_train_1m, X_test_1m, y_train_1m, y_test_1m = lstm_utils.split_train_test(df_time_series, [], in_seq_length=12, out_seq_length=1)\n",
    "\n",
    "# Check the shapes of the training and test data\n",
    "print(\"Shape of X_train:\", X_train_1m.shape)\n",
    "print(\"Shape of y_train:\", y_train_1m.shape)\n",
    "print(\"Shape of X_test:\", X_test_1m.shape)\n",
    "print(\"Shape of y_test:\", y_test_1m.shape)"
   ],
   "id": "a758546911c3a7a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([227, 1653, 12])\n",
      "Shape of y_train: torch.Size([227, 1653, 1])\n",
      "Shape of X_test: torch.Size([59, 1653, 12])\n",
      "Shape of y_test: torch.Size([59, 1653, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herbishtini/Documents/UNI/Master Thesis/sustainability_portfolio_optimisation/utilities/lstm_utils.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1724557170823/work/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  return (torch.tensor(x_ts, dtype=torch.float32),\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LSTM Univariate - 6 Months",
   "id": "43a9fdefde6c005"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:42.375641Z",
     "start_time": "2025-05-25T23:16:41.465039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(lstm_utils)\n",
    "\n",
    "# Set sequence length (e.g., 12 time points)\n",
    "X_train_6m, X_test_6m, y_train_6m, y_test_6m = lstm_utils.split_train_test(df_time_series, [], in_seq_length=12, out_seq_length=6)\n",
    "\n",
    "# Check the shapes of the training and test data\n",
    "print(\"Shape of X_train:\", X_train_6m.shape)\n",
    "print(\"Shape of y_train:\", y_train_6m.shape)\n",
    "print(\"Shape of X_test:\", X_test_6m.shape)\n",
    "print(\"Shape of y_test:\", y_test_6m.shape)"
   ],
   "id": "1696162ee878eb39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([227, 1653, 12])\n",
      "Shape of y_train: torch.Size([227, 1653, 6])\n",
      "Shape of X_test: torch.Size([54, 1653, 12])\n",
      "Shape of y_test: torch.Size([54, 1653, 6])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.372588Z",
     "start_time": "2025-05-25T23:16:42.394229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(lstm_utils)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model_6m = LSTMModel(input_size=12, output_size=12).to(device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model_6m.parameters(), lr=0.001)\n",
    "\n",
    "# @TODO resume here (fix test output)\n",
    "model, y_train_pred, y_test_pred = lstm_utils.lstm_train_validate(model_6m, optimizer, X_train_6m, X_test_6m, y_train_6m, y_test_6m)"
   ],
   "id": "10ce63dabded6f1d",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTMModel' object has no attribute 'train_predict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model_6m\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# @TODO resume here (fix test output)\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m model, y_train_pred, y_test_pred \u001B[38;5;241m=\u001B[39m lstm_utils\u001B[38;5;241m.\u001B[39mlstm_train_validate(model_6m, optimizer, X_train_6m, X_test_6m, y_train_6m, y_test_6m)\n",
      "File \u001B[0;32m~/Documents/UNI/Master Thesis/sustainability_portfolio_optimisation/utilities/lstm_utils.py:79\u001B[0m, in \u001B[0;36mlstm_train_validate\u001B[0;34m(model, optimizer, X_train, X_test, y_train, y_test)\u001B[0m\n\u001B[1;32m     76\u001B[0m y_train_pred \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([])\n\u001B[1;32m     77\u001B[0m y_test_pred \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([])\n\u001B[0;32m---> 79\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain_predict()\n\u001B[1;32m     80\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;66;03m# Train\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/portfolio_optimisation/lib/python3.11/site-packages/torch/nn/modules/module.py:1729\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1727\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1728\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1729\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LSTMModel' object has no attribute 'train_predict'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LSTM Univariate - 12 Months",
   "id": "f32c4b7502d9dfb9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train-Test Splits",
   "id": "6ce4ba4bb6d29a7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split the data into training and testing sets",
   "id": "ad62c65eeaec57a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.375468Z",
     "start_time": "2025-05-07T19:47:04.430055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(lstm_utils)\n",
    "\n",
    "# Set sequence length (e.g., 12 time points)\n",
    "X_train_12m, X_test_12m, y_train_12m, y_test_12m = lstm_utils.split_train_test(df_time_series, [], in_seq_length=12, out_seq_length=12)\n",
    "\n",
    "# Check the shapes of the training and test data\n",
    "print(\"Shape of X_train:\", X_train_12m.shape)\n",
    "print(\"Shape of y_train:\", y_train_12m.shape)\n",
    "print(\"Shape of X_test:\", X_test_12m.shape)\n",
    "print(\"Shape of y_test:\", y_test_12m.shape)"
   ],
   "id": "15a242ca157c28d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([227, 1653, 12])\n",
      "Shape of y_train: torch.Size([227, 1653, 12])\n",
      "Shape of X_test: torch.Size([48, 1653, 12])\n",
      "Shape of y_test: torch.Size([48, 1653, 12])\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.375681Z",
     "start_time": "2025-05-07T19:47:06.988366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model, Loss, Optimizer\n",
    "model_12m = LSTMModel(input_size=in_seq_length, output_size=out_seq_length).to(device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model_12m.parameters(), lr=0.001)"
   ],
   "id": "44c1702b803110f6",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.375748Z",
     "start_time": "2025-05-07T19:47:20.753314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "importlib.reload(lstm_utils)\n",
    "#\n",
    "model, y_train_pred, y_test_pred = lstm_utils.lstm_train_validate(model_12m, optimizer, X_train_12m, X_test_12m, y_train_12m, y_test_12m)"
   ],
   "id": "22cdddc240803495",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 31.5999, Train RMSE: 5.9694, Test RMSE: 0.2869. \n",
      "Model training complete and saved.\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.375815Z",
     "start_time": "2025-04-13T23:05:59.984302Z"
    }
   },
   "cell_type": "code",
   "source": "last_month = X_test_12m[[len(X_test_12m) - 1]]",
   "id": "113b405d49a85b6e",
   "outputs": [],
   "execution_count": 298
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.375874Z",
     "start_time": "2025-04-13T23:09:01.512441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    last_month_pred = model(last_month)"
   ],
   "id": "d767d07c58c6d7b5",
   "outputs": [],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T23:16:43.375926Z",
     "start_time": "2025-04-13T23:21:10.941085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Actual values\n",
    "y_test_12m = y_test_12m[len(y_test_12m) - 1][:, -1]\n",
    "# Predicted\n",
    "y_test_pred_12m = last_month_pred[0][:, -1]"
   ],
   "id": "765bc49dac33ad2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0553,  0.0107,  0.0534,  ...,  0.0438, -0.0076, -0.0185])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 312
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
